{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c28980f2",
   "metadata": {},
   "source": [
    "# Ingest and View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46c3038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834ac898",
   "metadata": {},
   "source": [
    "Creating connection to AWS Postgres database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20f0fa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSTGRES_USERNAME = 'root'\n",
    "POSTGRES_PASSWORD = 'koBREipm4h7CuRKix2Tn'\n",
    "POSTGRES_HOSTNAME = 'database-1.c3ma8u2guxxs.us-east-2.rds.amazonaws.com'\n",
    "POSTGRES_PORT = '5432'\n",
    "POSTGRES_DBNAME = 'postgres'\n",
    "\n",
    "connection_string = f\"postgresql://{POSTGRES_USERNAME}:{POSTGRES_PASSWORD}@{POSTGRES_HOSTNAME}:{POSTGRES_PORT}/{POSTGRES_DBNAME}\"\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92c5606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT * FROM darwin\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93623a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>service_start_date</th>\n",
       "      <th>update_origin</th>\n",
       "      <th>train_platform</th>\n",
       "      <th>working_time_pass</th>\n",
       "      <th>working_time_arrival</th>\n",
       "      <th>working_time_departure</th>\n",
       "      <th>planned_time_arrival</th>\n",
       "      <th>planned_time_departure</th>\n",
       "      <th>...</th>\n",
       "      <th>platform</th>\n",
       "      <th>train_length</th>\n",
       "      <th>estimated_time</th>\n",
       "      <th>source</th>\n",
       "      <th>actual_time</th>\n",
       "      <th>actual_time_class</th>\n",
       "      <th>is_delayed_arrival</th>\n",
       "      <th>is_delayed_departure</th>\n",
       "      <th>source_instance</th>\n",
       "      <th>estimated_time_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202407037139232</td>\n",
       "      <td>G39232</td>\n",
       "      <td>2024-07-03</td>\n",
       "      <td>TD</td>\n",
       "      <td>SCROYDN</td>\n",
       "      <td>None</td>\n",
       "      <td>19:31:00</td>\n",
       "      <td>19:31:30</td>\n",
       "      <td>19:31:00</td>\n",
       "      <td>19:31:00</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202407036785172</td>\n",
       "      <td>C85172</td>\n",
       "      <td>2024-07-03</td>\n",
       "      <td>CIS</td>\n",
       "      <td>LIVSTLL</td>\n",
       "      <td>None</td>\n",
       "      <td>19:37:00</td>\n",
       "      <td>19:38:00</td>\n",
       "      <td>19:37:00</td>\n",
       "      <td>19:38:00</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202407036735756</td>\n",
       "      <td>C35756</td>\n",
       "      <td>2024-07-03</td>\n",
       "      <td>TD</td>\n",
       "      <td>ESTHRAK</td>\n",
       "      <td>None</td>\n",
       "      <td>19:30:30</td>\n",
       "      <td>19:31:00</td>\n",
       "      <td>19:31:00</td>\n",
       "      <td>19:31:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202407036735756</td>\n",
       "      <td>C35756</td>\n",
       "      <td>2024-07-03</td>\n",
       "      <td>TD</td>\n",
       "      <td>BRMB</td>\n",
       "      <td>None</td>\n",
       "      <td>19:33:00</td>\n",
       "      <td>19:33:30</td>\n",
       "      <td>19:33:00</td>\n",
       "      <td>19:33:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202407036735756</td>\n",
       "      <td>C35756</td>\n",
       "      <td>2024-07-03</td>\n",
       "      <td>TD</td>\n",
       "      <td>BRMBRK</td>\n",
       "      <td>None</td>\n",
       "      <td>19:35:00</td>\n",
       "      <td>19:35:30</td>\n",
       "      <td>19:35:00</td>\n",
       "      <td>19:35:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          route_id unique_id service_start_date update_origin train_platform  \\\n",
       "0  202407037139232    G39232         2024-07-03            TD        SCROYDN   \n",
       "1  202407036785172    C85172         2024-07-03           CIS        LIVSTLL   \n",
       "2  202407036735756    C35756         2024-07-03            TD        ESTHRAK   \n",
       "3  202407036735756    C35756         2024-07-03            TD           BRMB   \n",
       "4  202407036735756    C35756         2024-07-03            TD         BRMBRK   \n",
       "\n",
       "  working_time_pass working_time_arrival working_time_departure  \\\n",
       "0              None             19:31:00               19:31:30   \n",
       "1              None             19:37:00               19:38:00   \n",
       "2              None             19:30:30               19:31:00   \n",
       "3              None             19:33:00               19:33:30   \n",
       "4              None             19:35:00               19:35:30   \n",
       "\n",
       "  planned_time_arrival planned_time_departure  ... platform train_length  \\\n",
       "0             19:31:00               19:31:00  ...        4         10.0   \n",
       "1             19:37:00               19:38:00  ...        A          NaN   \n",
       "2             19:31:00               19:31:00  ...        2          NaN   \n",
       "3             19:33:00               19:33:00  ...        1          NaN   \n",
       "4             19:35:00               19:35:00  ...        2          NaN   \n",
       "\n",
       "  estimated_time  source actual_time actual_time_class is_delayed_arrival  \\\n",
       "0           None    None        None              None              False   \n",
       "1           None    None        None              None              False   \n",
       "2           None    None        None              None              False   \n",
       "3           None    None        None              None              False   \n",
       "4           None    None        None              None              False   \n",
       "\n",
       "  is_delayed_departure  source_instance  estimated_time_minutes  \n",
       "0                False             None                    None  \n",
       "1                False             None                    None  \n",
       "2                False             None                    None  \n",
       "3                False             None                    None  \n",
       "4                False             None                    None  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b2d44a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 475574 entries, 0 to 475573\n",
      "Data columns (total 22 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   route_id                475574 non-null  object \n",
      " 1   unique_id               475574 non-null  object \n",
      " 2   service_start_date      475574 non-null  object \n",
      " 3   update_origin           463381 non-null  object \n",
      " 4   train_platform          475574 non-null  object \n",
      " 5   working_time_pass       0 non-null       object \n",
      " 6   working_time_arrival    475574 non-null  object \n",
      " 7   working_time_departure  475574 non-null  object \n",
      " 8   planned_time_arrival    436434 non-null  object \n",
      " 9   planned_time_departure  434539 non-null  object \n",
      " 10  actual_arrival_time     398845 non-null  object \n",
      " 11  actual_departure_time   443548 non-null  object \n",
      " 12  platform                445648 non-null  object \n",
      " 13  train_length            152597 non-null  float64\n",
      " 14  estimated_time          0 non-null       object \n",
      " 15  source                  0 non-null       object \n",
      " 16  actual_time             0 non-null       object \n",
      " 17  actual_time_class       0 non-null       object \n",
      " 18  is_delayed_arrival      475574 non-null  bool   \n",
      " 19  is_delayed_departure    475574 non-null  bool   \n",
      " 20  source_instance         0 non-null       object \n",
      " 21  estimated_time_minutes  0 non-null       object \n",
      "dtypes: bool(2), float64(1), object(19)\n",
      "memory usage: 73.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6b3ae2",
   "metadata": {},
   "source": [
    "# Clean DF \n",
    "**Drop Null Columns and Unnecessary Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1df2cd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd274c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 15180 duplicates in this dataset.\n"
     ]
    }
   ],
   "source": [
    "# check duplicates\n",
    "duplicates = df_cleaned.duplicated().sum()\n",
    "print(f'There are {duplicates} duplicates in this dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efb2d830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to drop duplicates\n",
    "df_cleaned = df_cleaned.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf90ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to drop due to null values or used in analysis\n",
    "columns_to_drop = [\n",
    "    'working_time_pass',\n",
    "    'estimated_time',\n",
    "    'source',\n",
    "    'actual_time',\n",
    "    'actual_time_class',\n",
    "    'source_instance',\n",
    "    'estimated_time_minutes',\n",
    "    'train_length', \n",
    "    'update_origin',\n",
    "    'planned_time_arrival',\n",
    "    'planned_time_departure',\n",
    "    'platform'\n",
    "]\n",
    "\n",
    "df_cleaned = df_cleaned.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1f48b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "route_id                      0\n",
       "unique_id                     0\n",
       "service_start_date            0\n",
       "train_platform                0\n",
       "working_time_arrival          0\n",
       "working_time_departure        0\n",
       "actual_arrival_time       76436\n",
       "actual_departure_time     31493\n",
       "is_delayed_arrival            0\n",
       "is_delayed_departure          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check nulls\n",
    "df_cleaned.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82f0c737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping the nulls reduces the rows of the dataset by 17.15%.\n"
     ]
    }
   ],
   "source": [
    "percent_dropped = round( ((1- (df_cleaned.dropna().shape[0]/df_cleaned.shape[0]))*100), 2)\n",
    "print(f'Dropping the nulls reduces the rows of the dataset by {percent_dropped}%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13284fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to drop remaining nulls\n",
    "# df_cleaned = df_cleaned.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddefcaf",
   "metadata": {},
   "source": [
    "# Create Delay DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99802c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_delay = \"SELECT * FROM darwin WHERE is_delayed_arrival = True AND is_delayed_departure = True\"\n",
    "df_delay = pd.read_sql(query_delay, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1586148",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay = df_delay.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a09e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375babaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14f58be",
   "metadata": {},
   "source": [
    "# Adding Duration Column\n",
    "Convert times from object datatypes to time datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8280cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['working_time_arrival'] = pd.to_datetime(df_cleaned['working_time_arrival'], format='%H:%M:%S')\n",
    "df_cleaned['working_time_departure'] = pd.to_datetime(df_cleaned['working_time_departure'], format='%H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2ec2df",
   "metadata": {},
   "source": [
    "Complete math to find duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbe480c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['duration (min)'] = ((df_cleaned['working_time_departure']-df_cleaned['working_time_arrival'])\\\n",
    "                                .dt.total_seconds()/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47503b6",
   "metadata": {},
   "source": [
    "Transition back to time only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe337fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['working_time_arrival'] = df_cleaned['working_time_arrival'].dt.time\n",
    "df_cleaned['working_time_departure'] = df_cleaned['working_time_departure'].dt.time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e24a1d7",
   "metadata": {},
   "source": [
    "Repeat for Delay Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9cd7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay['working_time_arrival'] = pd.to_datetime(df_delay['working_time_arrival'], format='%H:%M:%S')\n",
    "df_delay['working_time_departure'] = pd.to_datetime(df_delay['working_time_departure'], format='%H:%M:%S')\n",
    "df_delay['duration (min)'] = ((df_delay['working_time_departure']-df_delay['working_time_arrival'])\\\n",
    "                                .dt.total_seconds()/60)\n",
    "df_delay['working_time_arrival'] = df_delay['working_time_arrival'].dt.time\n",
    "df_delay['working_time_departure'] = df_delay['working_time_departure'].dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b58b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for zero and negative values\n",
    "neg_zero_duration_counts = df_cleaned[df_cleaned['duration (min)'] <= 0]['duration (min)'].value_counts().sort_index(ascending=True)\n",
    "\n",
    "# Display the result\n",
    "print(neg_zero_duration_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d350ebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows with negative values in duration\n",
    "df_cleaned = df_cleaned[df_cleaned['duration (min)'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6807cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "neg_zero_duration_counts = df_cleaned[df_cleaned['duration (min)'] <= 0]['duration (min)'].value_counts().sort_index(ascending=True)\n",
    "\n",
    "# Display the result\n",
    "print(neg_zero_duration_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d4523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeating Drop for delay_df to remove negative values in duration\n",
    "\n",
    "df_delay = df_delay[df_delay['duration (min)'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6835240e",
   "metadata": {},
   "source": [
    "## Adding a Day of the Week Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0439c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['service_start_date'] = pd.to_datetime(df_cleaned['service_start_date'])\n",
    "df_cleaned['weekday'] = df_cleaned['service_start_date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d5fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Top 10 most frequently visited stations\n",
    "weekday_dist = df_cleaned['weekday'].value_counts()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=weekday_dist.index, y=weekday_dist.values)\n",
    "plt.title('Weekday Distribution')\n",
    "plt.xlabel('Weekday')\n",
    "plt.ylabel('Number of Data Points')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe271e4",
   "metadata": {},
   "source": [
    "Keeping an eye on this distribtuion to try and keep data even across each weekday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ff6fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay['service_start_date'] = pd.to_datetime(df_delay['service_start_date'])\n",
    "df_delay['weekday'] = df_delay['service_start_date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8475a4e6",
   "metadata": {},
   "source": [
    "# Ingest Rail References Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690fe18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_df = pd.read_csv('./raw_data/RailReferences.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a8c505",
   "metadata": {},
   "source": [
    "## Convert Easting, Northing to Latitude and Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e763a765",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c6b1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d977b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Define the British National Grid projection (EPSG:27700) and WGS84\n",
    "osgb_projection = 'epsg:27700'  # British National Grid\n",
    "wgs84_projection = 'epsg:4326'  # WGS84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ae889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the transformer\n",
    "transformer = Transformer.from_crs(osgb_projection, wgs84_projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25e1eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert British National Grid to latitude and longitude\n",
    "def convert_osgb_to_latlong(easting, northing):\n",
    "    longitude, latitude = transformer.transform(easting, northing)\n",
    "    return longitude, latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c199522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply conversion to the DataFrame and create new columns Latitude and Longitude\n",
    "reference_df[['Latitude', 'Longitude']] = reference_df.apply(lambda row: convert_osgb_to_latlong(row['Easting'], row['Northing']),\\\n",
    "                                         axis=1,\\\n",
    "                                         result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2d5008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data need for analysis \n",
    "data = reference_df[['TiplocCode', 'StationName', 'Latitude', 'Longitude']]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d54f49",
   "metadata": {},
   "source": [
    "### Data Enrichment\n",
    "Used this section to add identifying information for top Timing Point Locations (*TiplocCode*) not already identified in the supplied \"RailReferences.csv\" data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e390b53c",
   "metadata": {},
   "source": [
    "Research indicates that the Timing Point Location for BONDST, correlates to Bond Street Station$^{1}$ located at 51.514Â°N, 0.15Â°W$^{2}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8430988",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = pd.DataFrame([['BONDST', 'Bond Street Station', 51.514, -0.15]], columns=data.columns)\n",
    "data = pd.concat([data, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d03be2",
   "metadata": {},
   "source": [
    "Research indicates that the Timing Point Location for TOTCTRD, correlates to Tottenham Court Road$^{1}$ located at 51.5207Â°N, 0.1345Â°W$^{3}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2bdeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = pd.DataFrame([['TOTCTRD', 'Tottenham Court Road', 51.5207, -0.1345]], columns=data.columns)\n",
    "data = pd.concat([data, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806afc4e",
   "metadata": {},
   "source": [
    "Research indicates that the Timing Point Location for CANWHRF, correlates to Canary Wharf Railway Station$^{1}$ located at 51.5061Â°N, 0.01578Â°W$^{4}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2763d27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = pd.DataFrame([['CANWHRF', 'Canary Wharf Railway Station', 51.5061, -0.01578]], columns=data.columns)\n",
    "data = pd.concat([data, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e94c0e",
   "metadata": {},
   "source": [
    "Research indicates that the Timing Point Location for WCHAPXR, correlates to Whitechapel Crossrail$^{1}$ located at 51.5195Â°N, 0.0612Â°W$^{5, 6}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd2e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = pd.DataFrame([['WCHAPXR', 'Whitechapel Crossrail', 51.9195, -0.0612]], columns=data.columns)\n",
    "data = pd.concat([data, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc21909",
   "metadata": {},
   "source": [
    "Research indicates that the Timing Point Location for LIVSTLL, correlates to London Liverpool Street Crossrail$^{1}$ located at 51.5186Â°N, 0.0813Â°W$^{6, 7}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8a1a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = pd.DataFrame([['LIVSTLL', 'London Liverpool Street Crossrail', 51.5186, -0.0813]], columns=data.columns)\n",
    "data = pd.concat([data, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454c1792",
   "metadata": {},
   "source": [
    "### Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1672783",
   "metadata": {},
   "source": [
    "1. http://www.railwaycodes.org.uk/crs/crsb.shtm\n",
    "\n",
    "2. https://en.wikipedia.org/wiki/Bond_Street_station\n",
    "\n",
    "3. https://en.wikipedia.org/wiki/Tottenham_Court_Road\n",
    "\n",
    "4. https://en.wikipedia.org/wiki/Canary_Wharf_railway_station\n",
    "\n",
    "5. https://en.wikipedia.org/wiki/Whitechapel_station\n",
    "\n",
    "6. https://en.wikipedia.org/wiki/Crossrail\n",
    "\n",
    "7. https://en.wikipedia.org/wiki/Liverpool_Street_station"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09df714",
   "metadata": {},
   "source": [
    "## Using Rail References to Replace Train Platform with Station Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5c7fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_cleaned with data columns from reference_df\n",
    "\n",
    "df_merged = df_cleaned.merge(data, left_on='train_platform', right_on='TiplocCode', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091f5b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking where train_platform has no related StationName/Tiploccode\n",
    "nan_rows = df_merged[df_merged[['TiplocCode', 'StationName']].isna().any(axis=1)]\n",
    "\n",
    "nan_rows[['train_platform', 'TiplocCode', 'StationName']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7658295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying most highly frequented unknown Station Names\n",
    "station_NaN = df_merged[df_merged['StationName'].isna()]['train_platform'].value_counts()\n",
    "station_NaN.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00c4fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NaN values in the StationName column with the corresponding train_platform values\n",
    "df_merged['StationName'] = df_merged['StationName'].fillna(df_merged['train_platform'])\n",
    "\n",
    "# Replace 'Rail Station' with an empty string to make more readable\n",
    "df_merged['StationName'] = df_merged['StationName'].str.replace(' Rail Station', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a275ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41974c07",
   "metadata": {},
   "source": [
    "## Adding a Day of the Wek Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3e58fb",
   "metadata": {},
   "source": [
    "# Delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc54f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay = df_delay.merge(data, left_on='train_platform', right_on='TiplocCode', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edc7989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NaN values in the StationName column with the corresponding train_platform values\n",
    "df_delay['StationName'] = df_delay['StationName'].fillna(df_delay['train_platform'])\n",
    "\n",
    "# Replace 'Rail Station' with an empty string to make more readable\n",
    "df_delay['StationName'] = df_delay['StationName'].str.replace(' Rail Station', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1692e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2753bee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc134dc8",
   "metadata": {},
   "source": [
    "Determine the minutes delayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015ff334",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay['working_time_arrival'] = pd.to_datetime(df_delay['working_time_arrival'], format='%H:%M:%S')\n",
    "df_delay['working_time_departure'] = pd.to_datetime(df_delay['working_time_departure'], format='%H:%M:%S')\n",
    "df_delay['duration (min)'] = ((df_delay['working_time_departure']-df_delay['working_time_arrival'])\\\n",
    "                                .dt.total_seconds()/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb82113",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay['actual_arrival_time'] = pd.to_datetime(df_delay['actual_arrival_time'], format='%H:%M:%S')\n",
    "df_delay['actual_departure_time'] = pd.to_datetime(df_delay['actual_departure_time'], format='%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e274bee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay['depart_delay(min)'] = ((df_delay['actual_departure_time']-df_delay['working_time_departure'])\\\n",
    "                                .dt.total_seconds()/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c2e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay['arrive_delay(min)'] = ((df_delay['actual_arrival_time']-df_delay['working_time_arrival'])\\\n",
    "                                .dt.total_seconds()/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff0d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay['working_time_arrival'] = df_delay['working_time_arrival'].dt.time\n",
    "df_delay['working_time_departure'] = df_delay['working_time_departure'].dt.time\n",
    "df_delay['actual_arrival_time'] = df_delay['actual_arrival_time'].dt.time\n",
    "df_delay['actual_departure_time'] = df_delay['actual_departure_time'].dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e933a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c24514",
   "metadata": {},
   "source": [
    "We can see that the math in the previous step created some erroneous values (minimum of depart_delay(min) is negative.) This will occur in cases where there is no reported actual_departure_time or where the train arrived slightly early. We will get the value zero where the train is not delayed. We will define a function to null delays less than or equal to zero, because these are erroneous on not delays at all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432ac7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_neg_and_zero(delay):\n",
    "    if delay <= 0:\n",
    "        delay = None\n",
    "    else:\n",
    "        delay = delay\n",
    "    return delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd917d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay['depart_delay(min)'] = df_delay['depart_delay(min)'].apply(remove_neg_and_zero)\n",
    "df_delay['arrive_delay(min)'] = df_delay['arrive_delay(min)'].apply(remove_neg_and_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad94c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc75b5de",
   "metadata": {},
   "source": [
    "We can see that the are some erroneous high values for depart_delay(min) and arrive_delay(min). We will remove any values over 420minutes (7hrs), assuming those trains are rescheduled rather than delayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a2df3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_over_420(delay):\n",
    "    if delay > 420:\n",
    "        delay = None\n",
    "    else:\n",
    "        delay = delay\n",
    "    return delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172c5f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay['depart_delay(min)'] = df_delay['depart_delay(min)'].apply(remove_over_420)\n",
    "df_delay['arrive_delay(min)'] = df_delay['arrive_delay(min)'].apply(remove_over_420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bed74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d408892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0e12b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export delay routes parquet\n",
    "df_delay.to_parquet('./cleaned_data/delay_durations.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b14f34",
   "metadata": {},
   "source": [
    "## Calculate Delay Duration\n",
    "Take the data where we are able to calucate delays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a512a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c9b801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 'delayed' column\n",
    "df_merged['delayed'] = df_merged['is_delayed_arrival'] | df_merged['is_delayed_departure']\n",
    "df_merged['delayed'] = df_merged['delayed'].astype(int)\n",
    "\n",
    "# Check\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548fbef0",
   "metadata": {},
   "source": [
    "## Delays  by Route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8cd932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the necessary columns\n",
    "df_extracted = df_merged[['route_id', 'delayed']]\n",
    "\n",
    "# Calculate the count of delays for each route_id and TiplocCode\n",
    "delay_counts_by_route = df_extracted.groupby('route_id')['delayed'].sum().reset_index()\n",
    "delay_counts_by_route.rename(columns={'delayed': 'delay_counts_by_route'}, inplace=True)\n",
    "\n",
    "# Calculate the total count of records for each route_id and TiplocCode\n",
    "total_counts_by_route = df_extracted.groupby('route_id')['route_id'].count().reset_index(name='total_counts_by_route')\n",
    "\n",
    "# Merge the delay counts and total counts\n",
    "delay_summary = delay_counts_by_route.merge(total_counts_by_route, on='route_id')\n",
    "\n",
    "# Calculate the % delayed for each route_id\n",
    "delay_summary['%_delayed_by_route'] = (delay_summary['delay_counts_by_route'] / delay_summary['total_counts_by_route']) * 100\n",
    "\n",
    "# Select the relevant columns\n",
    "delays_by_route = delay_summary[['route_id', 'delay_counts_by_route', 'total_counts_by_route', '%_delayed_by_route']]\n",
    "\n",
    "# Check\n",
    "delays_by_route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8642c696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export delay routes parquet\n",
    "delays_route = delays_by_route.to_parquet('./cleaned_data/delays_by_route.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f0c29b",
   "metadata": {},
   "source": [
    "## Delays by Station Name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0b0d4d",
   "metadata": {},
   "source": [
    "Changed to aggregate by TiplocCode, because upon further investigation it was found that a Station Name may have various TiplocCodes. Which would inflate the delay counts and station counts for each individual TiplocCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a131e773",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extracted2 = df_merged[['StationName', 'TiplocCode', 'delayed', 'Latitude', 'Longitude']]\n",
    "\n",
    "# Calculate the count of delays for each TiplocCode\n",
    "delay_counts_by_tiploc = df_extracted2.groupby('TiplocCode')['delayed'].sum().reset_index()\n",
    "delay_counts_by_tiploc.rename(columns={'delayed': 'delay_counts_by_tiploc'}, inplace=True)\n",
    "\n",
    "# Calculate the total count of records for each TiplocCode\n",
    "total_counts_by_tiploc = df_extracted2.groupby('TiplocCode')['TiplocCode'].count().reset_index(name='total_counts_by_tiploc')\n",
    "\n",
    "# Merge the delay counts and total counts\n",
    "delay_summary_tiploc = delay_counts_by_tiploc.merge(total_counts_by_tiploc, on='TiplocCode')\n",
    "\n",
    "# Calculate the % delayed for each TiplocCode\n",
    "delay_summary_tiploc['%_delayed_by_tiploc'] = (delay_summary_tiploc['delay_counts_by_tiploc'] / delay_summary_tiploc['total_counts_by_tiploc']) * 100\n",
    "\n",
    "# Select the relevant columns\n",
    "delays_by_tiploc = delay_summary_tiploc[['TiplocCode', 'delay_counts_by_tiploc', 'total_counts_by_tiploc', '%_delayed_by_tiploc']]\n",
    "\n",
    "# Merge the dataframes on 'TiplocCode' to add latitude, longitude, and StationName\n",
    "delays_by_tiploc = pd.merge(delays_by_tiploc, df_extracted2[['TiplocCode', 'StationName', 'Latitude', 'Longitude']].drop_duplicates(), on='TiplocCode', how='left')\n",
    "\n",
    "# Check\n",
    "delays_by_tiploc[delays_by_tiploc['StationName'] == 'Clapham Junction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d2dca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting delays by station to parquet\n",
    "delay_stations = delays_by_tiploc.to_csv('./cleaned_data/delays_by_station.csv', index=False, mode=\"w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4707667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how is_delayed arrivals/departures compare with delayed column\n",
    "df_merged['is_delayed_arrival'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7a760a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['is_delayed_departure'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e024e1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['delayed'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b45ae4",
   "metadata": {},
   "source": [
    "Delayed column has same counts as is_delayed_departure. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489d8839",
   "metadata": {},
   "source": [
    "# % Delayed by Weekday\n",
    "\n",
    "Create an aggregated dataframe to show the % of trains delayed by weekday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8bf3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the necessary columns\n",
    "df_weekday = df_merged[['weekday', 'delayed']].copy()\n",
    "df_weekday['count'] = 1\n",
    "df_weekday = df_weekday.groupby('weekday')[['delayed', 'count']].sum().reset_index()\n",
    "df_weekday['percent_delayed'] = (df_weekday['delayed'] / df_weekday['count'])*100\n",
    "df_weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba162f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weekday.to_csv('./cleaned_data/weekday_data.csv', index=False, mode= \"w+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e338505",
   "metadata": {},
   "source": [
    "# Value Counts for Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdee805",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['service_start_date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0628d3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most popular routes\n",
    "df_merged['route_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed2c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['StationName'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f155e58",
   "metadata": {},
   "source": [
    "# Visuals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5106922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Top 10 most frequently visited stations\n",
    "top_stations = df_merged['StationName'].value_counts().head(20)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=top_stations.index, y=top_stations.values)\n",
    "plt.title('Top 20 Most Frequently Visited Stations')\n",
    "plt.xlabel('Station')\n",
    "plt.ylabel('Number of Visits')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5b8854",
   "metadata": {},
   "source": [
    "The chart shows the top 20 most frequently visited stations in the UK rail system, revealing that 13 of these stations are in London. This highlights London's central role in the rail network, driven by its approximate population of 9 million, which constitutes about 13% of the UK's total population. Major hubs like Clapham Junction and London Bridge, as well as key interchange points and commuter stations, contribute to this high traffic, reflecting the substantial demand generated by the city's large population.\n",
    "\n",
    "Additionally, the chart underscores the importance of regional hubs such as Birmingham New Street, York, and Reading, which serve as central points for their areas, and the significance of rail connections to major airports like Gatwick. The presence of stations like City Thameslink and Whitechapel Crossrail also highlights the integration of various transport modes, providing seamless connectivity for passengers. Overall, London's dominance in the list illustrates its pivotal role in the UK's rail system, driven by its large population and economic activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee252b36",
   "metadata": {},
   "source": [
    "## Distribution of Station Counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2edeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts = df_merged['StationName'].value_counts().reset_index()\n",
    "df_counts.columns = ['StationName', 'Counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28eacd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x=df_counts['Counts'])\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbf74ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47bc82b",
   "metadata": {},
   "source": [
    "## Duration Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07670d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a748aa17",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Histogram for 'duration (min)'\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_merged['duration (min)'], bins=100, edgecolor='black')\n",
    "plt.title('Histogram of Duration (min)')\n",
    "plt.xlabel('Minutes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868124b3",
   "metadata": {},
   "source": [
    "Showing true "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1b2752",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Histogram for 'duration (min)' with smaller bins and logarithmic x-axis\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_merged['duration (min)'], bins=100, edgecolor='black', log=True)\n",
    "\n",
    "plt.title('Histogram of Duration (min) with Logarithmic Y-axis')\n",
    "plt.xlabel('Minutes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48952694",
   "metadata": {},
   "source": [
    "This histogram shows the distribution of trip durations from station to station with a logarithmic y-axis. The logarithmic scale is used to make it easier to see and understand data that has a very wide range by squeezing the numbers into a smaller, more readable format. The histogram reveals a high frequency of short trips, with the majority of trip durations clustered around the lower end, particularly between 0 and 50 minutes. There are significant drops in frequency as the duration increases, indicating that long trips are much less common. A few peaks at higher durations suggest some outliers where trips are unusually long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa7dcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot for 'duration (min)' with a logarithmic scale\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(df_merged['duration (min)'], vert=False, patch_artist=True, showfliers=True)\n",
    "plt.xscale('log')\n",
    "\n",
    "# Add mean and median lines\n",
    "mean_duration = df_merged['duration (min)'].mean()\n",
    "median_duration = df_merged['duration (min)'].median()\n",
    "mode_duration = df_merged['duration (min)'].mode().iloc[0]\n",
    "\n",
    "plt.axvline(mean_duration, color='r', linestyle='--', label=f'Mean: {mean_duration:.2f}')\n",
    "plt.axvline(median_duration, color='g', linestyle='-', label=f'Median: {median_duration:.2f}')\n",
    "plt.axvline(mode_duration, color='b', linestyle='-', label=f'Mode: {mode_duration:.2f}')\n",
    "\n",
    "plt.title('Boxplot of Duration (min) with Logarithmic Scale')\n",
    "plt.xlabel('Minutes (log scale)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc446c43",
   "metadata": {},
   "source": [
    "This boxplot provides a detailed summary of the distribution, highlighting the mean, median, and mode durations. The median trip duration is 1 minute, with a mean slightly higher at 1.48 minutes, indicating that the distribution is right-skewed with a long tail of longer durations. The mode is at 0.50 minutes, showing that very short trips are most common. The presence of numerous outliers further supports the observation from the histogram that while most trips are short, there are occasional long trips that are significantly longer than the majority. The logarithmic scale on the x-axis helps to spread out the data points, making it easier to see the distribution and identify the concentration of shorter trips and the spread of longer ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2073fecf",
   "metadata": {},
   "source": [
    "### Overall Analysis on Trip Duration Distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52ac76d",
   "metadata": {},
   "source": [
    "The analysis of trip durations reveals that the majority of trips are very short, with most durations clustered between 0 and 50 minutes. This trend makes sense given that the majority of trips occur in densely populated cities like London, where stations are closely spaced, and the demand for frequent, short commutes is high. In such urban environments, the transportation network is designed to handle large volumes of passengers moving over short distances, facilitating quick and efficient travel between closely situated stations.\n",
    "\n",
    "In cities like London, people often rely on the rail system for daily commutes, errands, and short-distance travel, contributing to the high frequency of brief trips. The shorter trips are reflective of the urban layout, where stations are strategically placed to maximize accessibility and convenience for city dwellers. The presence of numerous outliers with longer trip durations indicates occasional longer journeys, but these are less common. Overall, the data aligns with the expected travel patterns in a densely populated metropolitan area, emphasizing the importance of the rail network in supporting urban mobility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e331e2f8",
   "metadata": {},
   "source": [
    "## Delay Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d4116e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Arrival delay histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df_delay['arrive_delay(min)'], bins=20, color='blue')\n",
    "plt.title('Histogram of Arrival Delay (min)')\n",
    "plt.xlabel('Minutes')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Departure delay histogram\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df_delay['depart_delay(min)'], bins=20, color='green')\n",
    "plt.title('Histogram of Departure Delay (min)')\n",
    "plt.xlabel('Minutes')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92127739",
   "metadata": {},
   "source": [
    "The histograms display a high frequency of shorter delays, with most clustered between 0 and 50 minutes. As delay time increases, the frequency decreases, indicating that longer delays are less common. This right-skewed distribution shows that while shorter delays are frequent, longer delays, though less common, do occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e1160c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot boxplot for arrival_delay and depart_delay\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Adding mode \n",
    "arrival_mode = df_delay['arrive_delay(min)'].mode().iloc[0]\n",
    "depart_mode = df_delay['depart_delay(min)'].mode().iloc[0]\n",
    "\n",
    "# Arrival delay boxplot\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(x=df_delay['arrive_delay(min)'])\n",
    "plt.title('Boxplot of Arrival Delay (min)')\n",
    "plt.xlabel('Minutes')\n",
    "plt.axvline(df_delay['arrive_delay(min)'].mean(), color='red', linestyle='--', label=f'Mean: {df_delay[\"arrive_delay(min)\"].mean():.2f}')\n",
    "plt.axvline(df_delay['arrive_delay(min)'].median(), color='green', linestyle='-', label=f'Median: {df_delay[\"arrive_delay(min)\"].median():.2f}')\n",
    "plt.axvline(arrival_mode, color='b', linestyle='-', label=f'Mode: {arrival_mode:.2f}')\n",
    "plt.legend()\n",
    "\n",
    "# Departure delay boxplot\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x=df_delay['depart_delay(min)'])\n",
    "plt.title('Boxplot of Departure Delay (min)')\n",
    "plt.xlabel('Minutes')\n",
    "plt.axvline(df_delay['depart_delay(min)'].mean(), color='red', linestyle='--', label=f'Mean: {df_delay[\"depart_delay(min)\"].mean():.2f}')\n",
    "plt.axvline(df_delay['depart_delay(min)'].median(), color='green', linestyle='-', label=f'Median: {df_delay[\"depart_delay(min)\"].median():.2f}')\n",
    "plt.axvline(depart_mode, color='b', linestyle='-', label=f'Mode: {depart_mode:.2f}')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a056ee9c",
   "metadata": {},
   "source": [
    "Both boxplots show a substantial interquartile range (IQR), indicating a significant spread in the data. The median values for both arrival and departure delays are around 34.5 minutes and 36 minutes, respectively, suggesting that half of the delays are less than these values, while the other half are greater. The mean values for arrival and departure delays are slightly higher than the median values, at 46.9 minutes and 47.41 minutes, respectively. This discrepancy indicates a right-skewed distribution, with a tail extending towards higher delay times. This right-skewed distribution aligns with the histogram analysis, confirming that while most delays are within a reasonable range, there are instances of significantly longer delays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a3884a",
   "metadata": {},
   "source": [
    "**Relating back to the duration distribution**\n",
    "\n",
    "By comparing these observations with the distribution of trip duration, we can conclude that the UK's rail system experiences a higher frequency of shorter trips and moderate delays, with occasional long durations and severe delays that affect the overall average. This understanding can help in addressing the less frequent but impactful longer trips and delays to improve overall system efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1ac56b",
   "metadata": {},
   "source": [
    "# Export Desired Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59608c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = df_merged.to_parquet('./cleaned_data/UK_Rail_Data.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4144c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acd7ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a922a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
